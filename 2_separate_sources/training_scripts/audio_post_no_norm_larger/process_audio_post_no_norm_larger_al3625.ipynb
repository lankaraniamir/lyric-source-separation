{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import nussl\n",
    "import torch\n",
    "from nussl.datasets import transforms as nussl_tfm\n",
    "from common import utils, argbind\n",
    "import matplotlib.pyplot as plt\n",
    "from nussl.ml.networks.modules import AmplitudeToDB, BatchNorm, RecurrentStack, Embedding\n",
    "from nussl.separation.base import MaskSeparationBase, DeepMixin, SeparationException\n",
    "from torch import nn\n",
    "# from torch.nn.utils import weight_norm\n",
    "from ignite.engine import Events, Engine, EventEnum\n",
    "from nussl.ml import SeparationModel\n",
    "from nussl.ml.networks.modules import (\n",
    "    Embedding, DualPath, DualPathBlock, STFT, Concatenate, \n",
    "    LearnedFilterBank, AmplitudeToDB, RecurrentStack,\n",
    "    MelProjection, BatchNorm, InstanceNorm, ShiftAndScale\n",
    ")\n",
    "from torch import optim\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from setup_al3625 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.logger()\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "name = os.getcwd().split(\"/\")[-1]\n",
    "\n",
    "eval_folder = \"../../eval_results\"\n",
    "output_folder = os.path.join(\"../../trained_models\", name)\n",
    "results_folder = os.path.join(eval_folder, name)\n",
    "\n",
    "saved_model_best = os.path.join(output_folder, \"checkpoints/best.model.pth\")\n",
    "saved_model_new = os.path.join(output_folder, \"checkpoints/latest.model.pth\")\n",
    "saved_opt_best = os.path.join(output_folder, \"checkpoints/best.optimizer.pth\")\n",
    "saved_opt_new = os.path.join(output_folder, \"checkpoints/latest.optimizer.pth\")\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "if not os.path.exists(eval_folder):\n",
    "    os.mkdir(eval_folder)\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8 \n",
    "LEARNING_RATE = 1e-3 \n",
    "\n",
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128)\n",
    "nf = stft_params.window_length // 2 + 1\n",
    "\n",
    "keys = [\"posterior\"]\n",
    "post_depth=True\n",
    "use_corpus=False\n",
    "train_data, val_data, test_data = get_data(\"../../\", keys=keys, post_depth=post_depth, use_corpus=use_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosteriorModel(nn.Module):\n",
    "    def __init__(self, num_features, num_audio_channels, hidden_size,\n",
    "                 num_layers, bidirectional, dropout, num_sources, \n",
    "                activation='sigmoid'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.amplitude_to_db = AmplitudeToDB()\n",
    "        self.input_normalization = BatchNorm(num_features)\n",
    "\n",
    "        self.post_normalization = BatchNorm(41)\n",
    "        self.concatenate = Concatenate(dim = -2)\n",
    "\n",
    "        hidden_size = hidden_size + 41*3\n",
    "        self.recurrent_stack = RecurrentStack(\n",
    "            41*3 + num_features * num_audio_channels, hidden_size, \n",
    "            num_layers, bool(bidirectional), dropout, 'lstm'\n",
    "        )\n",
    "\n",
    "        hidden_size = hidden_size * (int(bidirectional) + 1)\n",
    "        self.embedding = Embedding(num_features, hidden_size, \n",
    "                                   num_sources, activation, \n",
    "                                   num_audio_channels)\n",
    "        \n",
    "    def forward(self, mix_magnitude, posterior):\n",
    "        mix_magnitude_db = self.amplitude_to_db(mix_magnitude)\n",
    "        mix_magnitude_norm = self.input_normalization(mix_magnitude_db)\n",
    "\n",
    "        combo_data = self.concatenate(mix_magnitude_norm, posterior)\n",
    "        stack_data = self.recurrent_stack(combo_data)\n",
    "        \n",
    "        mask = self.embedding(stack_data)\n",
    "        estimates = mix_magnitude.unsqueeze(-1) * mask\n",
    "        \n",
    "        output = {\n",
    "            'mask': mask,\n",
    "            'estimates': estimates\n",
    "        }\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    @argbind.bind_to_parser()\n",
    "    def build(num_features, num_audio_channels, hidden_size, \n",
    "              num_layers, bidirectional, dropout, num_sources,\n",
    "              activation='sigmoid'):\n",
    "        nussl.ml.register_module(PosteriorModel)\n",
    "        modules = {\n",
    "            'model': {\n",
    "                'class': 'PosteriorModel',\n",
    "                'args': {\n",
    "                    'num_features': num_features,\n",
    "                    'num_audio_channels': num_audio_channels,\n",
    "                    'hidden_size': hidden_size,\n",
    "                    'num_layers': num_layers,\n",
    "                    'bidirectional': bidirectional,\n",
    "                    'dropout': dropout,\n",
    "                    'num_sources': num_sources,\n",
    "                    'activation': activation\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        connections = [\n",
    "            ['model', ['mix_magnitude', 'posterior']]\n",
    "        ]\n",
    "        for key in ['mask', 'estimates']:\n",
    "            modules[key] = {'class': 'Alias'}\n",
    "            connections.append([key, [f'model:{key}']])\n",
    "        output = ['estimates', 'mask',]\n",
    "        config = {\n",
    "            'name': 'PosteriorModel',\n",
    "            'modules': modules,\n",
    "            'connections': connections,\n",
    "            'output': output\n",
    "        }\n",
    "        return nussl.ml.SeparationModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PosteriorModel.build(num_features=nf,\n",
    "                            num_audio_channels=1, \n",
    "                            hidden_size=512,\n",
    "                            num_layers=3,\n",
    "                            bidirectional=True, \n",
    "                            dropout=0.3, \n",
    "                            num_sources=1,\n",
    "                            activation='sigmoid')\n",
    "\n",
    "if os.path.exists(saved_model_new):\n",
    "    model_checkpoint = torch.load(saved_model_new)\n",
    "    model = SeparationModel(model_checkpoint[\"config\"]) \n",
    "    model.load_state_dict(model_checkpoint[\"state_dict\"])\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    optimizer_checkpoint =  torch.load(saved_opt_new)\n",
    "    optimizer.load_state_dict(optimizer_checkpoint)\n",
    "\n",
    "else:\n",
    "    model = PosteriorModel.build(num_features=nf,\n",
    "                             num_audio_channels=1, \n",
    "                             hidden_size=512,\n",
    "                             num_layers=3,\n",
    "                             bidirectional=True, \n",
    "                             dropout=0.3, \n",
    "                             num_sources=1, \n",
    "                             activation='sigmoid')\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nussl.ml.train.loss.L1Loss()\n",
    "def train_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_magnitudes']\n",
    "    )\n",
    "    loss.backward() # backwards + gradient step\n",
    "    optimizer.step()\n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    return loss_vals\n",
    "\n",
    "def val_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(data=batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_magnitudes']\n",
    "    )\n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    return loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, num_workers=4, batch_size=BATCH_SIZE)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_data, num_workers=4, batch_size=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, validator = modified_create_train_and_validation_engines(\n",
    "    train_step, val_step, device=DEVICE\n",
    ")\n",
    "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
    "nussl.ml.train.add_validate_and_checkpoint(output_folder, model,\n",
    "    optimizer, train_data, trainer, val_dataloader, validator)\n",
    "nussl.ml.train.add_progress_bar_handler(trainer, validator)\n",
    "\n",
    "if os.path.exists(saved_model_new):\n",
    "    trainer.load_state_dict(model_checkpoint[\"metadata\"][\"trainer.state_dict\"])\n",
    "    trainer.state.epoch_history = model_checkpoint[\"metadata\"][\"trainer.state.epoch_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training(engine):\n",
    "    plt.plot(trainer.state.iter_history['loss'])\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train Loss')\n",
    "    plt.show()\n",
    "\n",
    "    data = engine.state.epoch_history\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.subplot(111)\n",
    "    plt.plot(data['validation/L1Loss'], label='val')\n",
    "    plt.plot(data['train/L1Loss'], label='train')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "trainer.run(\n",
    "    train_dataloader,\n",
    "    max_epochs=EPOCHS\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "997c4558be07356c2b0a8bb58c51598cd0966f4bdac088ce10c0dada3ab32118"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
