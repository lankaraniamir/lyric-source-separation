{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import nussl\n",
    "import torch\n",
    "from nussl.datasets import transforms as nussl_tfm\n",
    "from common import utils, argbind\n",
    "import matplotlib.pyplot as plt\n",
    "from nussl.ml.networks.modules import AmplitudeToDB, BatchNorm, RecurrentStack, Embedding\n",
    "from nussl.separation.base import MaskSeparationBase, DeepMixin, SeparationException\n",
    "from torch import nn\n",
    "# from torch.nn.utils import weight_norm\n",
    "from ignite.engine import Events, Engine, EventEnum\n",
    "from nussl.ml import SeparationModel\n",
    "from nussl.ml.networks.modules import (\n",
    "    Embedding, DualPath, DualPathBlock, STFT, Concatenate, \n",
    "    LearnedFilterBank, AmplitudeToDB, RecurrentStack,\n",
    "    MelProjection, BatchNorm, InstanceNorm, ShiftAndScale\n",
    ")\n",
    "from torch import optim\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from setup_al3625 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.logger()\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "name = os.getcwd().split(\"/\")[-1]\n",
    "\n",
    "eval_folder = os.path.join(\"../../eval_results\", name)\n",
    "output_folder = os.path.join(\"../../trained_models\", name)\n",
    "results_folder = os.path.join(eval_folder, name)\n",
    "separator_folder = os.path.join(\"../../trained_models\", name, \"separator\")\n",
    "\n",
    "saved_model_best = os.path.join(output_folder, \"checkpoints/best.model.pth\")\n",
    "saved_model_new = os.path.join(output_folder, \"checkpoints/latest.model.pth\")\n",
    "saved_opt_best = os.path.join(output_folder, \"checkpoints/best.optimizer.pth\")\n",
    "saved_opt_new = os.path.join(output_folder, \"checkpoints/latest.optimizer.pth\")\n",
    "saved_separator = os.path.join(separator_folder, \"separator.model.pth\")\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "if not os.path.exists(eval_folder):\n",
    "    os.mkdir(eval_folder)\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "if not os.path.exists(separator_folder):\n",
    "    os.mkdir(separator_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8 \n",
    "LEARNING_RATE = 1e-3 \n",
    "\n",
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128)\n",
    "nf = stft_params.window_length // 2 + 1\n",
    "\n",
    "keys = []\n",
    "post_depth=False\n",
    "use_corpus=False\n",
    "only_audio=True\n",
    "train_data, val_data, test_data = get_data(\"../../\", keys=keys, post_depth=post_depth, use_corpus=use_corpus, audio_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosteriorModel(nn.Module):\n",
    "    def __init__(self, num_features, num_audio_channels, hidden_size,\n",
    "                 num_layers, bidirectional, dropout, num_sources, \n",
    "                activation='sigmoid'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.amplitude_to_db = AmplitudeToDB()\n",
    "        self.input_normalization = BatchNorm(num_features)\n",
    "\n",
    "        self.recurrent_stack = RecurrentStack(\n",
    "            num_features * num_audio_channels, hidden_size, \n",
    "            num_layers, bool(bidirectional), dropout, 'lstm'\n",
    "        )\n",
    "        hidden_size = hidden_size * (int(bidirectional) + 1)\n",
    "        self.embedding = Embedding(num_features, hidden_size, \n",
    "                                   num_sources, activation, \n",
    "                                   num_audio_channels)\n",
    "        \n",
    "    def forward(self, mix_magnitude):\n",
    "        mix_magnitude_db = self.amplitude_to_db(mix_magnitude)\n",
    "        mix_magnitude_norm = self.input_normalization(mix_magnitude_db)\n",
    "        stack_data = self.recurrent_stack(mix_magnitude_norm)\n",
    "        \n",
    "        mask = self.embedding(stack_data)\n",
    "        estimates = mix_magnitude.unsqueeze(-1) * mask\n",
    "        output = {\n",
    "            'mask': mask,\n",
    "            'estimates': estimates\n",
    "        }\n",
    "        return output\n",
    "        \n",
    "    @staticmethod\n",
    "    @argbind.bind_to_parser()\n",
    "    def build(num_features, num_audio_channels, hidden_size, \n",
    "              num_layers, bidirectional, dropout, num_sources,\n",
    "              activation='sigmoid'):\n",
    "        nussl.ml.register_module(PosteriorModel)\n",
    "        modules = {\n",
    "            'model': {\n",
    "                'class': 'PosteriorModel',\n",
    "                'args': {\n",
    "                    'num_features': num_features,\n",
    "                    'num_audio_channels': num_audio_channels,\n",
    "                    'hidden_size': hidden_size,\n",
    "                    'num_layers': num_layers,\n",
    "                    'bidirectional': bidirectional,\n",
    "                    'dropout': dropout,\n",
    "                    'num_sources': num_sources,\n",
    "                    'activation': activation\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        connections = [\n",
    "            ['model', ['mix_magnitude']]\n",
    "        ]\n",
    "        for key in ['mask', 'estimates']:\n",
    "            modules[key] = {'class': 'Alias'}\n",
    "            connections.append([key, [f'model:{key}']])\n",
    "        output = ['estimates', 'mask',]\n",
    "        config = {\n",
    "            'name': 'PosteriorModel',\n",
    "            'modules': modules,\n",
    "            'connections': connections,\n",
    "            'output': output\n",
    "        }\n",
    "        return nussl.ml.SeparationModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PosteriorModel.build(num_features=nf,\n",
    "                            num_audio_channels=1, \n",
    "                            hidden_size=512,\n",
    "                            num_layers=3,\n",
    "                            bidirectional=True, \n",
    "                            dropout=0.3, \n",
    "                            num_sources=1,\n",
    "                            activation='sigmoid')\n",
    "\n",
    "if os.path.exists(saved_model_new):\n",
    "    model_checkpoint = torch.load(saved_model_new)\n",
    "    model = SeparationModel(model_checkpoint[\"config\"]) \n",
    "    model.load_state_dict(model_checkpoint[\"state_dict\"])\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    optimizer_checkpoint =  torch.load(saved_opt_new)\n",
    "    optimizer.load_state_dict(optimizer_checkpoint)\n",
    "else:\n",
    "    model = PosteriorModel.build(num_features=nf,\n",
    "                             num_audio_channels=1, \n",
    "                             hidden_size=512,\n",
    "                             num_layers=3,\n",
    "                             bidirectional=True, \n",
    "                             dropout=0.3, \n",
    "                             num_sources=1, \n",
    "                             activation='sigmoid')\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nussl.ml.train.loss.L1Loss()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_magnitudes']\n",
    "    )\n",
    "    loss.backward() # backwards + gradient step\n",
    "    optimizer.step()\n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    return loss_vals\n",
    "\n",
    "def val_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_magnitudes']\n",
    "    )\n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    return loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    # train_data, num_workers=4, batch_size=BATCH_SIZE)\n",
    "    train_data, num_workers=0, batch_size=BATCH_SIZE)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    # val_data, num_workers=0, batch_size=BATCH_SIZE) \n",
    "    val_data, num_workers=0, batch_size=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, validator = modified_create_train_and_validation_engines(\n",
    "    train_step, val_step, device=DEVICE\n",
    ")\n",
    "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
    "nussl.ml.train.add_validate_and_checkpoint(output_folder, model,\n",
    "    optimizer, train_data, trainer, val_dataloader, validator)\n",
    "nussl.ml.train.add_progress_bar_handler(trainer, validator)\n",
    "\n",
    "if os.path.exists(saved_model_new):\n",
    "    trainer.load_state_dict(model_checkpoint[\"metadata\"][\"trainer.state_dict\"])\n",
    "    trainer.state.epoch_history = model_checkpoint[\"metadata\"][\"trainer.state.epoch_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/08/2023 01:20:02 AM | engine.py:876 Engine run resuming from iteration 3750, epoch 50 until 100 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2926e11d13c54951bf8dd757d270c267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/75]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/08/2023 01:21:22 AM | engine.py:992 Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[1;32m     17\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> 19\u001b[0m trainer\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     20\u001b[0m     train_dataloader,\n\u001b[1;32m     21\u001b[0m     max_epochs\u001b[39m=\u001b[39;49mEPOCHS\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/ignite/engine/engine.py:892\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mdataloader \u001b[39m=\u001b[39m data\n\u001b[1;32m    891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_run()\n\u001b[1;32m    893\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/ignite/engine/engine.py:935\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_generator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    934\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 935\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_run_generator)\n\u001b[1;32m    936\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m out:\n\u001b[1;32m    937\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_generator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/ignite/engine/engine.py:993\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEngine run is terminating due to exception: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_exception(e)\n\u001b[1;32m    995\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/ignite/engine/engine.py:638\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    637\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 638\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/ignite/engine/engine.py:959\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 959\u001b[0m epoch_time_taken \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    961\u001b[0m \u001b[39m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mtimes[Events\u001b[39m.\u001b[39mEPOCH_COMPLETED\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/ignite/engine/engine.py:1032\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mGET_BATCH_STARTED)\n\u001b[1;32m   1030\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1032\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mbatch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataloader_iter)\n\u001b[1;32m   1033\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mGET_BATCH_COMPLETED)\n\u001b[1;32m   1034\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/nussl/datasets/base_dataset.py:231\u001b[0m, in \u001b[0;36mBaseDataset.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m    230\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m i\n\u001b[0;32m--> 231\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(data)\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    234\u001b[0m         \u001b[39mraise\u001b[39;00m tfm\u001b[39m.\u001b[39mTransformException(\n\u001b[1;32m    235\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe output of transform must be a dictionary!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/nussl/datasets/transforms.py:795\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m    794\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m--> 795\u001b[0m         data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m    796\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    797\u001b[0m             \u001b[39mraise\u001b[39;00m TransformException(\n\u001b[1;32m    798\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe output of every transform must be a dictionary!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/nussl/datasets/transforms.py:231\u001b[0m, in \u001b[0;36mMagnitudeSpectrumApproximation.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mraise\u001b[39;00m TransformException(\n\u001b[1;32m    226\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmix_key\u001b[39m}\u001b[39;00m\u001b[39m in dictionary \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpassed to this Transform! Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(data\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    230\u001b[0m mixture \u001b[39m=\u001b[39m data[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmix_key]\n\u001b[0;32m--> 231\u001b[0m mixture\u001b[39m.\u001b[39;49mstft()\n\u001b[1;32m    232\u001b[0m mix_magnitude \u001b[39m=\u001b[39m mixture\u001b[39m.\u001b[39mmagnitude_spectrogram_data\n\u001b[1;32m    234\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mmix_magnitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m mix_magnitude\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/nussl/core/audio_signal.py:1010\u001b[0m, in \u001b[0;36mAudioSignal.stft\u001b[0;34m(self, window_length, hop_length, window_type, overwrite)\u001b[0m\n\u001b[1;32m   1007\u001b[0m window \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_window(window_type, window_length)\n\u001b[1;32m   1009\u001b[0m \u001b[39mfor\u001b[39;00m chan \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_channels():\n\u001b[0;32m-> 1010\u001b[0m     _, _, _stft \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49msignal\u001b[39m.\u001b[39;49mstft(\n\u001b[1;32m   1011\u001b[0m         chan, fs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_rate, window\u001b[39m=\u001b[39;49mwindow,\n\u001b[1;32m   1012\u001b[0m         nperseg\u001b[39m=\u001b[39;49mwindow_length, noverlap\u001b[39m=\u001b[39;49mwindow_length \u001b[39m-\u001b[39;49m hop_length)\n\u001b[1;32m   1013\u001b[0m     stft_data\u001b[39m.\u001b[39mappend(_stft)\n\u001b[1;32m   1015\u001b[0m stft_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(stft_data)\u001b[39m.\u001b[39mtranspose((\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/scipy/signal/_spectral_py.py:1211\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(x, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, boundary, padded, axis, scaling)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[39melif\u001b[39;00m scaling \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mspectrum\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1209\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter \u001b[39m\u001b[39m{\u001b[39;00mscaling\u001b[39m=}\u001b[39;00m\u001b[39m not in [\u001b[39m\u001b[39m'\u001b[39m\u001b[39mspectrum\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpsd\u001b[39m\u001b[39m'\u001b[39m\u001b[39m]!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1211\u001b[0m freqs, time, Zxx \u001b[39m=\u001b[39m _spectral_helper(x, x, fs, window, nperseg, noverlap,\n\u001b[1;32m   1212\u001b[0m                                     nfft, detrend, return_onesided,\n\u001b[1;32m   1213\u001b[0m                                     scaling\u001b[39m=\u001b[39;49mscaling, axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   1214\u001b[0m                                     mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mstft\u001b[39;49m\u001b[39m'\u001b[39;49m, boundary\u001b[39m=\u001b[39;49mboundary,\n\u001b[1;32m   1215\u001b[0m                                     padded\u001b[39m=\u001b[39;49mpadded)\n\u001b[1;32m   1217\u001b[0m \u001b[39mreturn\u001b[39;00m freqs, time, Zxx\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/scipy/signal/_spectral_py.py:1885\u001b[0m, in \u001b[0;36m_spectral_helper\u001b[0;34m(x, y, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode, boundary, padded)\u001b[0m\n\u001b[1;32m   1882\u001b[0m     freqs \u001b[39m=\u001b[39m sp_fft\u001b[39m.\u001b[39mrfftfreq(nfft, \u001b[39m1\u001b[39m\u001b[39m/\u001b[39mfs)\n\u001b[1;32m   1884\u001b[0m \u001b[39m# Perform the windowed FFTs\u001b[39;00m\n\u001b[0;32m-> 1885\u001b[0m result \u001b[39m=\u001b[39m _fft_helper(x, win, detrend_func, nperseg, noverlap, nfft, sides)\n\u001b[1;32m   1887\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m same_data:\n\u001b[1;32m   1888\u001b[0m     \u001b[39m# All the same operations on the y data\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m     result_y \u001b[39m=\u001b[39m _fft_helper(y, win, detrend_func, nperseg, noverlap, nfft,\n\u001b[1;32m   1890\u001b[0m                            sides)\n",
      "File \u001b[0;32m~/miniconda3/envs/sep/lib/python3.8/site-packages/scipy/signal/_spectral_py.py:1962\u001b[0m, in \u001b[0;36m_fft_helper\u001b[0;34m(x, win, detrend_func, nperseg, noverlap, nfft, sides)\u001b[0m\n\u001b[1;32m   1959\u001b[0m result \u001b[39m=\u001b[39m detrend_func(result)\n\u001b[1;32m   1961\u001b[0m \u001b[39m# Apply window by multiplication\u001b[39;00m\n\u001b[0;32m-> 1962\u001b[0m result \u001b[39m=\u001b[39m win \u001b[39m*\u001b[39;49m result\n\u001b[1;32m   1964\u001b[0m \u001b[39m# Perform the fft. Acts on last axis by default. Zero-pads automatically\u001b[39;00m\n\u001b[1;32m   1965\u001b[0m \u001b[39mif\u001b[39;00m sides \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtwosided\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training(engine):\n",
    "    plt.plot(trainer.state.iter_history['loss'])\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train Loss')\n",
    "    plt.show()\n",
    "    data = engine.state.epoch_history\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.subplot(111)\n",
    "    plt.plot(data['validation/L1Loss'], label='val')\n",
    "    plt.plot(data['train/L1Loss'], label='train')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "trainer.run(\n",
    "    train_dataloader,\n",
    "    max_epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = nussl.separation.deep.DeepMaskEstimation(\n",
    "    nussl.AudioSignal(), None, model_path=saved_model_best,\n",
    "    device=DEVICE\n",
    ")\n",
    "separator.model.save(saved_separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(test_data):\n",
    "    separator.audio_signal = item['mix']\n",
    "    separator.posterior = item['posterior']\n",
    "    item['posterior'].to(DEVICE)\n",
    "    estimates = separator()\n",
    "\n",
    "    source_keys = list(item['sources'].keys())\n",
    "    estimates = {\n",
    "        'vocals': estimates[0],\n",
    "        'non-vocals': item['mix'] - estimates[0]\n",
    "    }\n",
    "\n",
    "    sources = [item['sources'][k] for k in source_keys]\n",
    "    estimates = [estimates[k] for k in source_keys]\n",
    "\n",
    "    evaluator = nussl.evaluation.BSSEvalScale(\n",
    "        sources, estimates, source_labels=source_keys\n",
    "    )\n",
    "    scores = evaluator.evaluate()\n",
    "    output_file = os.path.join(eval_folder, f\"{i}.json\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(scores, f, indent=4)\n",
    "    if i % 5 == 0:\n",
    "        print([i], output_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = test_data[3]\n",
    "separator.audio_signal = item['mix']\n",
    "separator.posterior = item['posterior']\n",
    "estimates = separator()\n",
    "estimates.append(item['mix'] - estimates[0])\n",
    "visualize_masks(estimates)\n",
    "embed_audio(estimates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "997c4558be07356c2b0a8bb58c51598cd0966f4bdac088ce10c0dada3ab32118"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
